# Consistency

Coherency alone is not enough. In multicore systems we have more subtle conditions. Different variables are typically
used to control the behaviour of the program (e.g. entering a critical section).

Memory models arise: contracts between the hardware and the software on how the memory is laid out.

## Instruction reordering

In single core systems it's allowed to reorder the execution of independent of instructions. This does not alter the
semantics of the program.

Compiler reording is based on checking independent instructions to be reordered.

In multi-thread processors, the intended behaviour of the program is shared across theads:

Processor 1:

```c++
A = 5;
flag = 1;
```

Processor 2:

```c++
while(flag==0)
    ;

print A;
```

This a problem specific to multi-core shared memory programming.
What makes things worse is that there are multiple places in the system (from the language all the way down to the
processor) where instruction will be reordered.

Out-of-order execution is an exploitation of instruction level parallelism, entirely done by the hardware. A state of
the art single core computer could break the semantics of the program.

With shared memory programs, problems regarding reading and writing **different variables** arise.

One thing is program order, which is just defined by the order of load/stores appearing in each thread. Same thing
happens in all processors.

The operation order is across the load/stores of all threads interleaved. I then need a memory model.

A sequentially consistent memory system guarantees all these load/stores for a processor are sequential. Any
interleaving is legal like card shuffling. Independently of the ordering I cannot start and L/S before the previous are
completed.

> Sequential Consistency. If the result of any execution is the same as if the operations were executed in some
sequential order.

This is our canonical model.

I can't have "Hello World" because there is a cross control flow dependence, under sequential consistency.
Can be implemented bu delays the completion of any memory access until all invalidations.

## Relaxed memory consistency models

Partially allow R/W to complete out of order. This is not about dependencies, but unrelated load and stores.

If I relax W -> R, I get processor consistency or total store ordering.

If I relax W -> W i get partial store order and I allow writes to bypass earlier writes.

If I relax R -> W and R -> R I have release consistency and weak ordering (Alpha, PowerPC)

We're interested in relaxing the ordering requirements since accessing memory is costly. We want to hide the memory
latency and overlap independent memory accesses with other operations.

Hide latency of writes achieved by TSO and PC. This is why every modern system implements a sort of write buffer,
interposed between the processor and the memory hierarchy. These are also referred ghosted writes.

Regular ILP reordering: allow read after write of different variables.

Under TSO a processor P can read 

Under PS any processor can read new value of A before the write is observed by all processors.
