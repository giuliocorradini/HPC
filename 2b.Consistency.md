# Consistency

Coherency alone is not enough. In multicore systems we have more subtle conditions. Different variables are typically
used to control the behaviour of the program (e.g. entering a critical section).

Memory models arise: contracts between the hardware and the software on how the memory is laid out.

## Instruction reordering

In single core systems it's allowed to reorder the execution of independent of instructions. This does not alter the
semantics of the program.

Compiler reording is based on checking independent instructions to be reordered.

In multi-thread processors, the intended behaviour of the program is shared across theads:

Processor 1:

```c++
A = 5;
flag = 1;
```

Processor 2:

```c++
while(flag==0)
    ;

print A;
```

This a problem specific to multi-core shared memory programming.
What makes things worse is that there are multiple places in the system (from the language all the way down to the
processor) where instruction will be reordered.

Out-of-order execution is an exploitation of instruction level parallelism, entirely done by the hardware. A state of
the art single core computer could break the semantics of the program.

With shared memory programs, problems regarding reading and writing **different variables** arise.

One thing is program order, which is just defined by the order of load/stores appearing in each thread. Same thing
happens in all processors.

The operation order is across the load/stores of all threads interleaved. I then need a memory model.

A sequentially consistent memory system guarantees all these load/stores for a processor are sequential. Any
interleaving is legal like card shuffling. Independently of the ordering I cannot start and L/S before the previous are
completed.

> Sequential Consistency. If the result of any execution is the same as if the operations were executed in some
sequential order.

This is our canonical model.

I can't have "Hello World" because there is a cross control flow dependence, under sequential consistency.
Can be implemented bu delays the completion of any memory access until all invalidations.

## Relaxed memory consistency models

Partially allow R/W to complete out of order. This is not about dependencies, but unrelated load and stores.

If I relax W -> R, I get processor consistency or total store ordering.

If I relax W -> W i get partial store order and I allow writes to bypass earlier writes.

If I relax R -> W and R -> R I have release consistency and weak ordering (Alpha, PowerPC)

We're interested in relaxing the ordering requirements since accessing memory is costly. We want to hide the memory
latency and overlap independent memory accesses with other operations.

Hide latency of writes achieved by TSO and PC. This is why every modern system implements a sort of write buffer,
interposed between the processor and the memory hierarchy. These are also referred ghosted writes.

Regular ILP reordering: allow read after write of different variables.

Under TSO a processor P can read 

Under PS any processor can read new value of A before the write is observed by all processors.

##Â Wrapping up

The problem is related to different processors accessing shared memory. We want to share variables between processors,
that are not correlated to each other in the single program.

T1:

```c++
A = 5;
flag = 1;
```

T2:

```
while(flag == 0);
print A;
```

we have an inconsistency problem if T1 reorders instruction (which is legal in single-threaded application and does
not alter the semantics of the program).

The reordering might happen in the compiler, but in hardware too (exploiting ILP). Out of order execution allows to
reorder instructions indeeed provided there are no dependencies.

So we have to agree on how the system behaves in memory reorderings.

## Weak ordering

Or weak consistency, a system that does not provide any guarantee. You would do very little. You manually take care of
those case where you need load/store.

Just like test&set or compare&swap, we create new instructions called _memory fences_ that prevents any type of reordering
in the hardware and in the compiler. This is not a barrier.

With this model, you need to place fences in critical points. This is really point-to-point optimization of the program.
Consistency is too conservative, but we don't care about that. The case I need ordering in L/S are rare, so it's better
to place fences. Compilers can be instructed to where to place fences automatically.

## Release consistency

Refers to the observation that most of parallel programs are already synchronized. Fence can be implicit upon synchronization
so implicit in others.

Load and stores relevant to the semantics of the program are ordered.

Under release consistency mostly your release instructions have an implied fence, so you're guaranteed memory consistency.
