## Performance

When acquiring a lock you need to undergo a certain type of operation, this is the **latency**. Since I'm not the the only
thread competing for a lock I will see an increase in latency from my POV.

The measure of latency should not be take into account the **contention**: the time for me to acquire the lock in the system
when competing.

**Bandwidth** is especially important under contention: how long does it take for my operation to complete?

**Traffic** is another important property related to how many events on shared resources. Different locking algorithm
have different impact on traffic. We don't want additional pressure on the bus.

**Storage** you need to keep track of additional information: which threads are trying to acquire a lock? In certain
schemes this overseen, in others it's kept in sight.

Finally **fairness**, it's not really about the guaranteeing that we have correct semantics, but it's more about being
*fair*. Some implementation tend to favor some threads, and that create imbalance. Fairness is not a functional property
related to the fact that a parallel system works properly if there aren't imbalancements.

## Coherency for Test&Set

Test&Set reads then writes, it always generates coherency transactions.

Ideally there's only one bus transaction involved per lock event. But what we see is that time increases. We need to
reason to release the pressure.

The idea is you don't need to check the status of the lock in t&s mode all the time. T&S has a write (the update).
But I just need to check whether the lock is free. _Test&Test&Set_

```c++
void lock(volatile int *lock) {
    while(true) {
        while (*lock != 0)
            if (test_and_test(*lock) == 0)
                return;
    }
}

void unlock(volatile int *lock) {
    lock = 0;
}
```

the scheme is not as predictable as befor, but it's better than actively signaling processors. It's more scalable as
this generates less traffic.

The storage cost remains unchanged: they both require a single variable. Very little footprint in memory. But there aren't
any provisions for fairness.

### Backoff

Metaphore of the public toilet: if the toilet is occupied it isn't wise to constantly check but better check after an
amount of time.

Initially wait for a small time, if the resource is busy I wait for a longer time. If the delay increases by a factor
of 2 it's called exponential backoff.

Good points: it generates less traffic and improve scalability. Storage cost unchanged.

But exponential backoff can cause sever unfairness. The more you miss the more time you're delayed. Most programs gave
synchronization barries and this is a problem, since a single thread can increasy latency for the whole program.

### Ticket lock

The data structure is not a single variable where I'm keeping track of the number of threads requiring the resource,
and the "now serving" variable.

```c
struct lock {
    volatile int next_ticket;
    volatile int now_serving;
}
```

The lock function atomically increments the `next_ticket` field. This design does not require a test and set by design.
This is deterministic.

### Array-based lock

```c
struct lock {
    volatile int status[P];
    volatile int head;
}
```

Constant traffic generated but only requires linear space.

IDLE versions of the waiting - if you also care about energy consumption - implement a literal freeze of the core.
You just remove the clock signal which is an easy way of lowering the power consumption. You're getting rid of the dynamic
power, but static power remains unchanged (bias currents). Shutting down removes all consumption altogether.

This makes the system less reactive.
