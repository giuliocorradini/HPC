# On GPU programming

Dedicated hardware such as ASICs completely lacks flexibility and have high costs, that only big players can afford.

GPUs tend to sit between fully hardware implementations and CPUs. They're 3 to 4 orders of magnitude more efficient than
CPUs.

In between we have FPGAs, which is full hardware implementation of functionality, but it's not really printed. It's
reconfiguration of this hardware that provides flexibility.

GPUs bear for graphics. Overtime people realize that this type of parallelism is abundant in linear lagebra, deep learning
etc.
GPUs designers realised that by designing their GPUs in a slightly different manner, they could take the market of high
performance numerical computation that was looking more and more into accelerated solutions.

The original task of GPUs was to compute polygons, texture mapping and shading. Therefore the cores are called Shader Cores,
then a number of other units doing very specific activities.

In a typical CPU you have the usual pipeline stages, with fetch/decode unit, ALU, register file and data cache to hide
the big latency of memory.
On top of that we may want to add branch prediction to avoid starving the pipeline, pre-fetching...

### Paradigm shift

Since I'm dealing with very specific type of operation, that heavily relies on data parallelism, maybe I don't need the
hardware for components that helps a single instruction stream run faster.

We can replicate several times this very simple unit to perform computations. Now I have lots of ALUs, F/D units and
execution contexts.

But looking even more carefully, as I'm most concerned about data parallelism. Why do I need to care about multiple F/D
units? The only benefit is to drive different ALUs with different instructions but that's not our case.

> Let's have a single fetch/decode unit that drives multiple ALUs, and have a shared context data. That's why GPUs are
not so good on general purpose computations, since you have a single fetch/decode unit that imposes sequential execution.

Now we have something more similar to a SIMD unit. We don't refer to GPUs as several cores, but only a bunch of cores that
have very large SIMD units.

Let's say you have an NVIDIA GPU with 16 SM, each having 128 CUDA cores. The CUDA cores are the ALUs and provide the SIMD
width.
