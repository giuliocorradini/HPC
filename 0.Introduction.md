# Introduction

In this course we are going to learn about parallel programming models and we're get to know them with the hands-on
laboratories. OpenMP and CUDA are two programming languages for parallel models, based on C/C++. OpenMP abstracts the
parallelization and is focused on integrating the notion of parallelism in your standard programming workflow, whilst
CUDA is more focused on low level performance and leaves to the programmer the task of laying out the memory.
We will also learn the basics of HLS for FPGA programming.

The course is divided in three modules:

1. modern architectures for HPC (multi-core CPUs and memory organization, GPGPUs, FPGAs). The i in iGPU means integrated,
and the main advantage is a reduced delay for data to be moved around in memory. In external GPUs the time required for
data to be moved from the main memory to the GPU RAM is a lot higher since it has to go through different systems (PCIe).

2. parallel programming and acceleration: programming models and performance issues will be explored. Devkit need to have
introspection (through the exploitation of available interfaces) for debugging and programming.

    On the CPU we will be using OpenMP, for CUDA we'll be using a custom devkit for the Nvidia Tegra chip. For HLS we'll be using a Xilinx Zynq FPGA.

    An FPGA chip can morph to whatever circuit you like.

3. hands on labs

## Supercomputing

Super computer always involve many computers interconnected that carry out a single task.

Supercomputing is nowadays available to a limited extent in our pockets: smartphones have and have had multiple cores for
years and are becoming system-on-chips. SoC have different chips on the same die, it's interconnected with very low
latency buses since everything lays near.

Supercomputing is a matter of distributed systems, while parallel code handles tasks that are computed (with distribution)
but in processors that are near.

Parallel programming twenty years ago was a niche of topic reserved to numerical simulations on large scale. Today mobile
devices are inherently parallel.
